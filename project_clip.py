# -*- coding: utf-8 -*-
"""PROJECT_CLIP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R6bdntjvjBXnqTZ8ukw8fZHONqp7gn0c

DATA
"""

!pip install gdown

# Chuẩn bị dữ liệu
!gdown 1wHYMj-E63l30O6tD8U-ZL92fT-d08d0d


# Giải nén
!unzip Charts.zip

# Cài cắm thư viện
!pip -q install sentence-transformers
!pip -q install faiss-cpu

import os
from glob import glob
from PIL import Image
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import matplotlib.pyplot as plt
import random

# Show thử 1 vài hình ảnh trong bộ dữ liệu
image_folder ="/content/Charts"

# Lấy danh sách file trong thư mục hình ảnh
image_files = glob(os.path.join(image_folder, "*.jpg"))

# Chọn ngẫu nhiên 5 hình ảnh
selected_files = random.sample(image_files, 5)

plt.figure(figsize=(20, 5))
for i, file in enumerate(selected_files):
    image = Image.open(file)
    plt.subplot(1, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')

plt.show()

"""Triển khai mô hình CLIP và xử lý ảnh"""

# Tạo embedding cho ảnh bằng model
model = SentenceTransformer('clip-ViT-B-32')
image_path = "/content/Charts"

image_files = glob(os.path.join(image_path, "*.jpg"))
embeddings = []

for image_file in image_files:
    #Mở từng file ảnh
    image = Image.open(image_file)

    #Sử dụng model mã hóa từng ảnh, lưu vào image_embedding
    image_embedding = model.encode(image)

    #Lưu phần mã hóa vừa rồi vào trong danh sách embedding
    embeddings.append(image_embedding)

    print(len(image_embedding))

# Dựng lên vectorDB với FAISS
dimension = len(embeddings[0]) #Số chiều của vector được mã hóa
index = faiss.IndexFlatIP(dimension) #Khởi tạo index dựa trên tích vô hướng
index = faiss.IndexIDMap(index)

vectors = np.array(embeddings).astype('float32') #chuyển về numpy array
index.add_with_ids(vectors, np.array(range(len(embeddings))))

# Save index vào file
faiss.write_index(index, "index.faiss")

# Ghi các tên ảnh vào tệp tin để load khi cần
with open("image_files.txt", "w") as f:
    for image_file in image_files:
        f.write(image_file + "\n")

def search_image(query, model, index, image_files, top_k=2):
    if query.endswith(".jpg"): #nếu query là ảnh
        query = Image.open(query) #mở ảnh

    query_embedding = model.encode(query) #mã hóa query
    query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1) #chuyển về dạng numpy vector

    distances, indices = index.search(query_embedding, top_k) #tìm k kết quả phù hợp nhất dựa trên kết quả tích vô hướng

    retrieved_images = [image_files[i] for i in indices[0]] #lưu danh sách các ảnh

    return query, retrieved_images #trả về kết quả tìm được

query = 'flower chart' #tên truy vấn
query, retrieved_images = search_image(query, model, index, image_files, top_k = 5) #kết quả truy vấn

def visualize_results(query, retrieved_images): #hiển thị ảnh
  plt.figure(figsize=(20, 5))
  for i, file in enumerate(retrieved_images): #duyệt qua các ảnh
      image = Image.open(file) #mở từng ảnh một
      plt.subplot(1, len(retrieved_images), i + 1)
      plt.imshow(image)
      plt.axis('off')
  plt.show()

visualize_results(query=query, retrieved_images=retrieved_images)

"""Recall và Precision"""

!pip install ftfy regex tqdm
!pip install git+https://github.com/openai/CLIP.git

import torch
import clip
from PIL import Image
import os
import json
from tqdm import tqdm

correct_image = [
      "/content/Charts/chart12.jpg",
      "/content/Charts/chart34.jpg",
      "/content/Charts/chart35.jpg",
      "/content/Charts/chart36.jpg",
      "/content/Charts/chart40.jpg",
      "/content/Charts/chart41.jpg",
      "/content/Charts/chart119.jpg",
      "/content/Charts/chart120.jpg",
      "/content/Charts/chart127.jpg",
      "/content/Charts/chart128.jpg",
      "/content/Charts/chart129.jpg",
      "/content/Charts/chart130.jpg",
      "/content/Charts/chart9.jpg",
      "/content/Charts/chart13.jpg",
      "/content/Charts/chart11.jpg",
      "/content/Charts/chart10.jpg",
      "/content/Charts/chart1.jpg",
      "/content/Charts/chart2.jpg",
      "/content/Charts/chart5.jpg",
      "/content/Charts/chart3.jpg",
      "/content/Charts/chart4.jpg",
      "/content/Charts/chart17.jpg",
      "/content/Charts/chart18.jpg",
      "/content/Charts/chart19.jpg",
      "/content/Charts/chart20.jpg",
      "/content/Charts/chart21.jpg",
      "/content/Charts/chart22.jpg",
      "/content/Charts/chart33.jpg",
      "/content/Charts/chart25.jpg",
      "/content/Charts/chart26.jpg",
      "/content/Charts/chart27.jpg",
      "/content/Charts/chart31.jpg",
      "/content/Charts/chart32.jpg",
      "/content/Charts/chart38.jpg",
      "/content/Charts/chart39.jpg",
      "/content/Charts/chart42.jpg",
      "/content/Charts/chart43.jpg",
      "/content/Charts/chart44.jpg",
      "/content/Charts/chart46.jpg",
      "/content/Charts/chart45.jpg",
      "/content/Charts/chart46.jpg",
      "/content/Charts/chart48.jpg",
      "/content/Charts/chart49.jpg",
      "/content/Charts/chart50.jpg",
      "/content/Charts/chart52.jpg",
      "/content/Charts/chart53.jpg",
      "/content/Charts/chart157.jpg",
      "/content/Charts/chart158.jpg",
      "/content/Charts/chart159.jpg",
      "/content/Charts/chart186.jpg",
      "/content/Charts/chart187.jpg",
    ]

from PIL import Image
from tqdm import tqdm
import torch
import clip

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# Danh sách ảnh đã có sẵn
image_paths = correct_image

# Tiền xử lý và mã hóa ảnh
image_tensors = [
    preprocess(Image.open(p).convert("RGB")).unsqueeze(0).to(device)
    for p in tqdm(image_paths)
]
image_input = torch.cat(image_tensors)

# Mã hóa ảnh bằng CLIP
with torch.no_grad():
    image_features = model.encode_image(image_input)
    image_features /= image_features.norm(dim=-1, keepdim=True)

query_list = [
    {
        "query": "layer of the earth",
        "correct_image": [
            "/content/Charts/chart12.jpg",
            "/content/Charts/chart34.jpg",
            "/content/Charts/chart35.jpg",
            "/content/Charts/chart36.jpg"
        ]
    },
    {
        "query": "fishbone diagram",
        "correct_image": [
            "/content/Charts/chart40.jpg",
            "/content/Charts/chart41.jpg"
        ]
    },
    {
        "query": "turtle life cycle",
        "correct_image": [
            "/content/Charts/chart119.jpg",
            "/content/Charts/chart120.jpg"
        ]
    },
    {
        "query": "bee life cycle",
        "correct_image": [
            "/content/Charts/chart127.jpg",
            "/content/Charts/chart128.jpg"
        ]
    },
    {
        "query": "bee make honey",
        "correct_image": [
            "/content/Charts/chart129.jpg",
            "/content/Charts/chart130.jpg"
        ]
    },
    {
        "query": "rock cycle",
        "correct_image": [
            "/content/Charts/chart9.jpg",
            "/content/Charts/chart13.jpg",
            "/content/Charts/chart11.jpg",
            "/content/Charts/chart10.jpg"
        ]
    },
    {
        "query": "carbon cycle",
        "correct_image": [
            "/content/Charts/chart1.jpg",
            "/content/Charts/chart2.jpg",
            "/content/Charts/chart5.jpg"
        ]
    },
    {
        "query": "water cycle",
        "correct_image": [
            "/content/Charts/chart3.jpg",
            "/content/Charts/chart4.jpg"
        ]
    },
    {
        "query": "photosynthesis",
        "correct_image": [
            "/content/Charts/chart17.jpg",
            "/content/Charts/chart18.jpg",
            "/content/Charts/chart19.jpg"
        ]
    },
    {
        "query": "nitrogen cycle",
        "correct_image": [
            "/content/Charts/chart20.jpg",
            "/content/Charts/chart21.jpg",
            "/content/Charts/chart22.jpg",
            "/content/Charts/chart33.jpg"
        ]
    },
    {
        "query": "layers of soil",
        "correct_image": [
            "/content/Charts/chart25.jpg",
            "/content/Charts/chart26.jpg",
            "/content/Charts/chart27.jpg"
        ]
    },
    {
        "query": "roles of a river",
        "correct_image": [
            "/content/Charts/chart31.jpg",
            "/content/Charts/chart32.jpg"
        ]
    },
    {
        "query": "biome",
        "correct_image": [
            "/content/Charts/chart38.jpg",
            "/content/Charts/chart39.jpg"
        ]
    },
    {
        "query": "transpiration",
        "correct_image": [
            "/content/Charts/chart42.jpg",
            "/content/Charts/chart43.jpg"
        ]
    },
    {
        "query": "animal cell",
        "correct_image": [
            "/content/Charts/chart44.jpg",
            "/content/Charts/chart46.jpg"
        ]
    },
    {
        "query": "plant cell",
        "correct_image": [
            "/content/Charts/chart45.jpg",
            "/content/Charts/chart46.jpg"
        ]
    },
    {
        "query": "flower structure",
        "correct_image": [
            "/content/Charts/chart48.jpg",
            "/content/Charts/chart49.jpg",
            "/content/Charts/chart50.jpg"
        ]
    },
    {
        "query": "protein synthesis",
        "correct_image": [
            "/content/Charts/chart52.jpg",
            "/content/Charts/chart53.jpg"
        ]
    },
    {
        "query": "solar system",
        "correct_image": [
            "/content/Charts/chart157.jpg",
            "/content/Charts/chart158.jpg",
            "/content/Charts/chart159.jpg"
        ]
    },
    {
        "query": "composition blood",
        "correct_image": [
            "/content/Charts/chart186.jpg",
            "/content/Charts/chart187.jpg"
        ]
    }
]

import torch
from PIL import Image
import matplotlib.pyplot as plt
import clip
import os

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# correct_image là danh sách đường dẫn ảnh
image_paths = correct_image
image_path_map = {os.path.basename(p): p for p in image_paths}

# Mã hóa ảnh
image_tensors = [preprocess(Image.open(p).convert("RGB")).unsqueeze(0).to(device) for p in image_paths]
image_input = torch.cat(image_tensors)

with torch.no_grad():
    image_features = model.encode_image(image_input)
    image_features /= image_features.norm(dim=-1, keepdim=True)

# Giả sử query_list có dạng: [{"query": "văn bản", "correct_image": [path1, path2]}]
precision_total = 0
recall_total = 0
total = len(query_list)

for q in query_list:
    query = q["query"]
    gt = [os.path.basename(p) for p in q["correct_image"]]

    # Mã hóa truy vấn
    text_input = clip.tokenize([query]).to(device)
    with torch.no_grad():
        text_features = model.encode_text(text_input)
        text_features /= text_features.norm(dim=-1, keepdim=True)

    # Tính độ tương đồng và lấy top-3
    sims = (image_features @ text_features.T).squeeze(1)
    top3_idx = sims.topk(3).indices.tolist()
    preds = [os.path.basename(image_paths[i]) for i in top3_idx]

    # Precision@3 và Recall@3
    num_correct = sum(1 for name in preds if name in gt)
    precision = num_correct / 3
    recall = 1 if any(name in gt for name in preds) else 0

    precision_total += precision
    recall_total += recall

    # In kết quả
    print(f"\n Query: {query}")
    print(f" Ground truth: {gt}")
    print(f" Top-3 predictions: {preds}")

    # Hiển thị ảnh top-3
    for i, name in enumerate(preds):
        img = Image.open(image_path_map[name])
        plt.subplot(1, 3, i + 1)
        plt.imshow(img)
        plt.title("Đúng " if name in gt else "Sai")
        plt.axis('off')
    plt.suptitle(query)
    plt.show()

# Tổng kết
print(f"\n Precision@3: {precision_total / total:.2%}")
print(f" Recall@3: {recall_total / total:.2%}")

import matplotlib.pyplot as plt

metrics = ['Precision@3', 'Recall@3']
values = [precision, recall]

plt.bar(metrics, values, color=['blue', 'green'])
plt.title('Evaluation Metrics')
plt.ylim(0, 1)
plt.show()

import os
import clip
import torch
from PIL import Image

# Load the model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load('ViT-B/32', device)

# Giả sử 'image' đã được load ở các cell trước.
# Nếu không, bạn cần load ảnh bạn muốn phân loại ở đây, ví dụ:
# image = Image.open("/content/Charts/chart12.jpg")

# Lấy danh sách các truy vấn từ query_list
# query_list được định nghĩa ở các cell trước
queries = [q["query"] for q in query_list]

# Chuẩn bị input cho ảnh đơn lẻ
image_input = preprocess(image).unsqueeze(0).to(device)

# Chuẩn bị input cho các truy vấn văn bản
text_inputs = torch.cat([clip.tokenize(q) for q in queries]).to(device)

# Tính features (embedding)
with torch.no_grad():
    image_features = model.encode_image(image_input)
    text_features = model.encode_text(text_inputs)

# Chuẩn hóa features
image_features /= image_features.norm(dim=-1, keepdim=True)
text_features /= text_features.norm(dim=-1, keepdim=True)

# Tính độ tương đồng
# (100.0 * image_features @ text_features.T) sẽ cho ma trận độ tương đồng
# softmax(dim=-1) để chuyển thành xác suất
similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)

# Lấy 5 truy vấn có độ tương đồng cao nhất
values, indices = similarity[0].topk(5)

# In kết quả
print("\nTop predictions based on queries:\n")
for value, index in zip(values, indices):
    print(f"{queries[index]:>16s}: {100 * value.item():.2f}%")

# Bạn cũng có thể hiển thị ảnh được phân loại nếu muốn
plt.imshow(image)
plt.title("correct")
plt.axis('off')
plt.show()